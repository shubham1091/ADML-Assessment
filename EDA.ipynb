{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a8433e9",
   "metadata": {},
   "source": [
    "# National Energy Consortium (NEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b83765a",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "- **Objective**: Select one plant form 64 options to serve each demand scenario\n",
    "- **Goal**: Minimise cost (UDS/MWh) for meeting demand\n",
    "- **Error Metrics**: RMSE between optimal and selected plant costs\n",
    "- **Data**: 3 Datasets (demand, plants, generations_costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44765ba4",
   "metadata": {},
   "source": [
    "### Error metric\n",
    "\n",
    "The per-scenario error is defined as:\n",
    "\n",
    "$$\n",
    "\\text{Error}(d) \\;=\\; \\min_{p \\in P} c(p, d) \\;-\\; c(p'_d, d)\n",
    "$$\n",
    "\n",
    "- d: a demand scenario  \n",
    "- P: set of candidate plants (64 options)  \n",
    "- p: a plant in P  \n",
    "- p'_d: the plant selected for scenario d by the model/heuristic  \n",
    "- c(p, d): cost (UDS/MWh) of plant p under scenario d\n",
    "\n",
    "Notes:\n",
    "- This computes the difference between the optimal (minimum) cost across all plants for scenario d and the cost of the selected plant.  \n",
    "- Use these per-scenario errors to compute aggregate metrics (e.g., RMSE, MAE) across all scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63b5460",
   "metadata": {},
   "source": [
    "### Score (RMSE)\n",
    "\n",
    "The aggregate error score (root-mean-square error) across demand scenarios is:\n",
    "\n",
    "$$\n",
    "\\text{Score} \\;=\\; \\sqrt{\\frac{1}{D}\\sum_{d=1}^{D}\\text{Error}(d)^2}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- D: total number of demand scenarios  \n",
    "- Error(d): per-scenario error (as defined earlier, Error(d) = min_{p in P} c(p,d) - c(p'_d,d))\n",
    "\n",
    "This score summarizes the typical magnitude of the per-scenario selection error (lower is better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "223e0900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneGroupOut, GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import json\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d61657",
   "metadata": {},
   "source": [
    "\n",
    "#### Helper classes and Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d7d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger:\n",
    "    def __init__(self, verbose: bool = True):\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def header(self, text:str, width:int=80):\n",
    "        if self.verbose:\n",
    "            print(\"=\"*width)\n",
    "            print(text)\n",
    "            print(\"=\"*width)\n",
    "    \n",
    "    def subheader(self,text:str):\n",
    "        if self.verbose:\n",
    "            print(f\"\\n{text}\")\n",
    "            print(\"-\")*len(text)\n",
    "            \n",
    "    def info(self, text:str, indent:int=0):\n",
    "        if self.verbose:\n",
    "            print(\" \"*indent + f\"✔ {text}\")\n",
    "    \n",
    "    def data(self, text:str, indent: int=0):\n",
    "        if self.verbose:\n",
    "            print(\" \"*indent + f\"➤ {text}\")\n",
    "    \n",
    "    def metric(self, label:str, value: Any, unit:str=\"\", indent:int=0):\n",
    "        if self.verbose:\n",
    "            print(\" \"*indent +f\" {label}: {value} {unit}\")\n",
    "        \n",
    "    def success(self, text:str):\n",
    "        if self.verbose:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"✔ {text}\")\n",
    "            print(f\"{'='*80}\\n\")\n",
    "        \n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class StepConfig:\n",
    "    name: str\n",
    "    description: str\n",
    "    verbose: bool = True\n",
    "\n",
    "class Step:\n",
    "    def __init__(self, config:Optional[StepConfig]=None):\n",
    "        self.config = config or StepConfig(\"Step\",\"Generic Step\")\n",
    "        self.logger = Logger(verbose=self.config.verbose) \n",
    "\n",
    "    def execute(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"Execute method must be implemented by subclasses\")\n",
    "    \n",
    "    def get_results(self) -> Dict[str, Any]:\n",
    "        raise NotImplementedError(\"get_results method must be implemented by subclasses\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51e22b8",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "In the data preparation stage, please adopt a comprehensive approach, addressing the following areas:\n",
    "1. **Handle any missing data** by identifying and managing incomplete records or missing values to ensure the dataset is ready for further analysis.\n",
    "2. **Perform relevant feature selection** by determining which features are most important for your goal. Additionally, apply feature scaling to normalise the data and ensure all featues contribute equally to the model, avoiding biases due to deffering ranges.\n",
    "3. **Focus on identifying the top-performing plants** for each demand by analysing the cost data. Since not all plants perform equally well, you should remove the worst-performing plants from the dataset to make the following tasks more manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55bfb451",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparation(Step):\n",
    "    def __init__(self, config:Optional[StepConfig]=None):\n",
    "        super().__init__(config or StepConfig(\"Step 1\", \"Data Preparation\"))\n",
    "        \n",
    "        ## Results storage\n",
    "        self.demand_df_clean = None\n",
    "        self.plants_df_filtered = None\n",
    "        self.costs_df_filtered = None\n",
    "        self.demand_features = None\n",
    "        self.plant_features = None\n",
    "        self.metadata = {}\n",
    "        \n",
    "    @staticmethod\n",
    "    def validate_features(df:pd.DataFrame, prefix:str)->List[str]:\n",
    "        features = [col for col in df.columns if col.startswith(prefix) and pd.api.types.is_numeric_dtype(df[col])]\n",
    "        return features\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_missing_stats(df:pd.DataFrame, columns:List[str])-> Dict[str,Any]:\n",
    "        total = len(df)\n",
    "        missing = df[columns].isnull().sum().sum()\n",
    "        missing_pct = 100 * missing / (len(columns)*total) if total > 0 else 0\n",
    "        \n",
    "        ## Calculate mean/std only on numeric columns\n",
    "        numeric_cols = [col for col in columns if pd.api.types.is_numeric_dtype(df[col])]\n",
    "        simple_mean = df[numeric_cols].values.mean() if numeric_cols else 0\n",
    "        simple_std = df[numeric_cols].values.std() if numeric_cols else 0\n",
    "        \n",
    "        return {\n",
    "            \"total_records\": total,\n",
    "            \"missing_count\": missing,\n",
    "            \"missing_percent\": missing_pct,\n",
    "            \"feature_count\": len(columns),\n",
    "            \"simple_mean\": simple_mean,\n",
    "            \"simple_std\": simple_std\n",
    "        }\n",
    "    \n",
    "    def fit_transform(self, demand_df:pd.DataFrame, plants_df:pd.DataFrame, demand_features: List[str], plant_features:List[str])-> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        scaler_demand = StandardScaler()\n",
    "        scaler_plants = StandardScaler()\n",
    "        \n",
    "        demand_df_scaled = demand_df.copy()\n",
    "        plants_df_scaled = plants_df.copy()\n",
    "        \n",
    "        demand_df_scaled[demand_features] = scaler_demand.fit_transform(demand_df[demand_features])\n",
    "        plants_df_scaled[plant_features] = scaler_plants.fit_transform(plants_df[plant_features])\n",
    "        \n",
    "        return demand_df_scaled, plants_df_scaled\n",
    "    \n",
    "    def analyse_plants(self, costs_df:pd.DataFrame) -> Dict[str, Any]:\n",
    "        plant_stats = costs_df.groupby(\"Plant ID\")[\"Cost_USD_per_MWh\"].agg([\"median\",\"mean\", \"count\"]).sort_values(by=\"median\")\n",
    "        \n",
    "        threshold_cost = plant_stats[\"median\"].quantile(75/100)\n",
    "        worst_plants = plant_stats[plant_stats[\"median\"]> threshold_cost].index.tolist()\n",
    "        good_plants = plant_stats[plant_stats[\"median\"]<= threshold_cost].index.tolist()\n",
    "        \n",
    "        return {\n",
    "            \"stats\": plant_stats,\n",
    "            \"threshold\": threshold_cost,\n",
    "            \"worst_plants\": worst_plants,\n",
    "            \"good_plants\": good_plants\n",
    "        }\n",
    "    \n",
    "    def filter_data(self, demand_df:pd.DataFrame, plants_df:pd.DataFrame, costs_df:pd.DataFrame, good_plants:List[str]) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "        \n",
    "        plants_filtered = plants_df[plants_df[\"Plant ID\"].isin(good_plants)].reset_index(drop=True)\n",
    "        costs_filtered = costs_df[(costs_df[\"Demand ID\"].isin(demand_df[\"Demand ID\"])) & (costs_df[\"Plant ID\"].isin(good_plants))].reset_index(drop=True)\n",
    "        \n",
    "        return demand_df, plants_filtered, costs_filtered\n",
    "    \n",
    "    def _print_summary(self):\n",
    "        def _safe_len(obj):\n",
    "            return len(obj) if obj is not None else 0\n",
    "\n",
    "        print(\"Data Preparation Summary:\")\n",
    "        print(f\"  - Demand scenarios: {_safe_len(self.demand_df_clean)}\")\n",
    "        print(f\"  - Plants: {_safe_len(self.plants_df_filtered)}\")\n",
    "        print(f\"  - Cost records: {_safe_len(self.costs_df_filtered)}\")\n",
    "        print(f\"  - Demand features: {_safe_len(self.demand_features)}\")\n",
    "        print(f\"  - Plant features: {_safe_len(self.plant_features)}\")\n",
    "    \n",
    "    def get_results(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"demand_df\": self.demand_df_clean,\n",
    "            \"plants_df\": self.plants_df_filtered,\n",
    "            \"costs_df\": self.costs_df_filtered,\n",
    "            \"demand_features\": self.demand_features,\n",
    "            \"plant_features\": self.plant_features,\n",
    "            \"metadata\": self.metadata\n",
    "        }\n",
    "            \n",
    "    def execute(self, demand_path:str, plants_path:str, costs_path:str):\n",
    "        \n",
    "        ## Load data\n",
    "        demand_df = pd.read_csv(demand_path, keep_default_na=False, na_values=[\"\"])\n",
    "        plants_df = pd.read_csv(plants_path, keep_default_na=False, na_values=[\"\"])\n",
    "        costs_df = pd.read_csv(costs_path, keep_default_na=False, na_values=[\"\"])\n",
    "        \n",
    "        ## Handle missing values\n",
    "        demand_feature_cols = self.validate_features(demand_df, \"DF\")\n",
    "        self.demand_features = demand_feature_cols\n",
    "        \n",
    "        missing_stats = self.get_missing_stats(demand_df, demand_feature_cols)\n",
    "        \n",
    "        demand_df_clean = demand_df.copy()\n",
    "        demand_df_clean[demand_feature_cols] = demand_df_clean[demand_feature_cols].fillna(demand_df_clean[demand_feature_cols].mean())\n",
    "        \n",
    "        ## Feature scaling\n",
    "        plant_feature_cols = self.validate_features(plants_df, \"PF\")\n",
    "        self.plant_features = plant_feature_cols\n",
    "        \n",
    "        demand_df_scaled, plants_df_scaled = self.fit_transform(demand_df_clean, plants_df, self.demand_features, self.plant_features)\n",
    "        \n",
    "        \n",
    "        ## Remove worst performing plants\n",
    "        plant_analysis = self.analyse_plants(costs_df)\n",
    "        \n",
    "        demand_df_final, plant_df_filtered, costs_df_filtered = self.filter_data(demand_df_scaled, plants_df_scaled, costs_df, plant_analysis[\"good_plants\"])\n",
    "        \n",
    "        ## Store results\n",
    "        self.demand_df_clean = demand_df_final\n",
    "        self.plants_df_filtered = plant_df_filtered\n",
    "        self.costs_df_filtered = costs_df_filtered\n",
    "        \n",
    "        ## remove NaN cost values\n",
    "        nan_costs = self.costs_df_filtered[\"Cost_USD_per_MWh\"].isna().sum()\n",
    "        if nan_costs > 0:\n",
    "            self.costs_df_filtered = self.costs_df_filtered.dropna(subset=[\"Cost_USD_per_MWh\"])\n",
    "        \n",
    "        ## Store metadata\n",
    "        self.metadata = {\n",
    "            \"demand_featues\": self.demand_features,\n",
    "            \"plant_features\": self.plant_features,\n",
    "            \"missing_stats\": missing_stats,\n",
    "            \"plant_analysis\": plant_analysis\n",
    "        }\n",
    "        \n",
    "        ## Print summary\n",
    "        self._print_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3561789e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation Summary:\n",
      "  - Demand scenarios: 500\n",
      "  - Plants: 48\n",
      "  - Cost records: 23927\n",
      "  - Demand features: 12\n",
      "  - Plant features: 18\n"
     ]
    }
   ],
   "source": [
    "step_one = DataPreparation()\n",
    "step_one.execute(\n",
    "    demand_path=\"Data/raw/demand.csv\",\n",
    "    plants_path=\"Data/raw/plants.csv\",\n",
    "    costs_path=\"Data/raw/generation_costs.csv\"\n",
    ")\n",
    "step_one_results = step_one.get_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
